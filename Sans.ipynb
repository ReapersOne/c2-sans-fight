{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d810585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Tuple\n",
    "from keras.api.models import Sequential\n",
    "from keras.api.layers import Dense\n",
    "from keras.api.optimizers import Adam\n",
    "from collections import deque\n",
    "from IPython.display import IFrame\n",
    "import pyautogui\n",
    "import random\n",
    "\n",
    "from Config.sansConfig import ScreenConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15022cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95    # discount rate\n",
    "        self.epsilon = 1.0   # exploration rate\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.001\n",
    "        self.model = self._build_model()\n",
    "    \n",
    "    def _build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, input_dim=self.state_size, activation='relu'))\n",
    "        model.add(Dense(24, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values[0])\n",
    "    \n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = reward + self.gamma * np.amax(self.model.predict(next_state)[0])\n",
    "            target_f = self.model.predict(state)\n",
    "            target_f[0][action] = target\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "# You would need to modify the game to:\n",
    "# 1. Provide state observations (player position, bullet positions, etc.)\n",
    "# 2. Accept discrete actions (move left, right, up, down, etc.)\n",
    "# 3. Calculate rewards (survival time, damage dealt, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e159e9e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"https://jcw87.github.io/c2-sans-fight/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x178871207c0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(src=\"https://jcw87.github.io/c2-sans-fight/\", width=800, height=600)  # Replace with your hosted URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcdd75a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "# Launch Chrome and load the game\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://jcw87.github.io/c2-sans-fight/\")  # Hosted game URL\n",
    "time.sleep(2)  # Wait for game to load\n",
    "\n",
    "# Focus the game window\n",
    "driver.find_element(\"tag name\", \"body\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7bff993a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_google_rect() -> dict[str : Tuple[int, int]]:\n",
    "        game_rect : dict[str : Tuple[int, int]] = {}\n",
    "\n",
    "        browser_window = pyautogui.getWindowsWithTitle(\"Bad Time Simulator\")[0]  # or \"Chrome\" if that's what appears in the title\n",
    "        \n",
    "        # Get window coordinates\n",
    "        x, y = browser_window.left, browser_window.top\n",
    "        width, height = browser_window.width, browser_window.height\n",
    "        \n",
    "        # Adjust these values to capture just the game area (not the browser UI)\n",
    "        game_x = x + 10  # Add padding to skip browser borders\n",
    "        game_y = y + 100  # Skip address bar and tabs\n",
    "        game_width = width - 20\n",
    "        game_height = height - 120\n",
    "\n",
    "        game_rect[\"corrdinates\"] = [game_x, game_y]\n",
    "        game_rect[\"scale\"] = [game_width, game_height]\n",
    "\n",
    "        return game_rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1df3e961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import ImageGrab\n",
    "\n",
    "\n",
    "def get_game_state():\n",
    "    # Capture the game area (adjust coordinates to match the IFrame)\n",
    "    rect = get_google_rect()\n",
    "    x = rect[\"corrdinates\"][0]\n",
    "    y = rect[\"corrdinates\"][1]\n",
    "\n",
    "    width = rect[\"scale\"][0]\n",
    "    height = rect[\"scale\"][1]\n",
    "\n",
    "    screenshot = ImageGrab.grab(bbox=(x, y, x+width, y+height))  # Replace with your IFrame position\n",
    "    screenshot = np.array(screenshot)\n",
    "    screenshot = cv2.cvtColor(screenshot, cv2.COLOR_RGB2GRAY)  # Convert to grayscale\n",
    "    screenshot = cv2.resize(screenshot, (84, 84))  # Resize for DQN input\n",
    "    return screenshot\n",
    "\n",
    "state = get_game_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b09489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def player_hit(state):\n",
    "    # Check if player's red heart pixel is missing (got hit)\n",
    "    return state[player_y, player_x] != RED_VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "de277d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_action(action):\n",
    "    body = driver.find_element(\"tag name\", \"body\")\n",
    "    if action == 0:    # Move left\n",
    "        body.send_keys(Keys.ARROW_LEFT)\n",
    "    elif action == 1:  # Move right\n",
    "        body.send_keys(Keys.ARROW_RIGHT)\n",
    "    elif action == 2:  # Move up\n",
    "        body.send_keys(Keys.ARROW_UP)\n",
    "    elif action == 3:  # Move down\n",
    "        body.send_keys(Keys.ARROW_DOWN)\n",
    "    elif action == 4:  # Attack (Z key)\n",
    "        body.send_keys(\"z\")\n",
    "    elif action == 5:  # Do nothing\n",
    "        pass  # No action, do nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b544f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward(prev_state, current_state):\n",
    "    # Check if player got hit (pixel color change)\n",
    "    if player_hit(current_state):\n",
    "        return -10  # Penalty for getting hit\n",
    "    else:\n",
    "        return 1   # Reward for surviving each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe73653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.api.models import Sequential\n",
    "from keras.api.layers import Dense, Conv2D, Flatten\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self):\n",
    "        self.state_size = (84, 84, 1)  # Grayscale image dims\n",
    "        self.action_size = 5  # [Left, Right, Up, Down, Attack]\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95\n",
    "        self.epsilon = 1.0\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, (8, 8), strides=4, activation='relu', input_shape=self.state_size))\n",
    "        model.add(Conv2D(64, (4, 4), strides=2, activation='relu'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(256, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer='adam')\n",
    "        return model\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        state = np.expand_dims(state, axis=0)\n",
    "        act_values = self.model.predict(state, verbose=0)\n",
    "        return np.argmax(act_values[0])\n",
    "\n",
    "    def train(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = reward + self.gamma * np.amax(self.model.predict(next_state, verbose=0)[0])\n",
    "            target_f = self.model.predict(state, verbose=0)\n",
    "            target_f[0][action] = target\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        if self.epsilon > 0.01:\n",
    "            self.epsilon *= 0.995\n",
    "\n",
    "agent = DQNAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302e7ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "episodes = 1000\n",
    "\n",
    "for e in range(episodes):\n",
    "    driver.refresh()  # Reset game\n",
    "    time.sleep(2)\n",
    "    state = get_game_state()\n",
    "    state = np.expand_dims(state, axis=-1)  # Add channel dim\n",
    "    total_reward = 0\n",
    "    \n",
    "    while True:\n",
    "        action = agent.act(state)\n",
    "        take_action(action)\n",
    "        time.sleep(0.05)  # Adjust for game speed\n",
    "        \n",
    "        next_state = get_game_state()\n",
    "        next_state = np.expand_dims(next_state, axis=-1)\n",
    "        reward = get_reward(state, next_state)\n",
    "        done = check_game_over(next_state)  # Implement this\n",
    "        \n",
    "        agent.memory.append((state, action, reward, next_state, done))\n",
    "        total_reward += reward\n",
    "        state = next_state\n",
    "        \n",
    "        if done:\n",
    "            print(f\"Episode: {e}, Reward: {total_reward}\")\n",
    "            break\n",
    "        \n",
    "        if len(agent.memory) > batch_size:\n",
    "            agent.train(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92580279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def player_hit(state):\n",
    "    # Check if player's red heart pixel is missing (got hit)\n",
    "    return state[player_y, player_x] != RED_VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827f4c76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyautogui'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25184\\4277297073.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImageGrab\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpyautogui\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_game_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyautogui'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import ImageGrab\n",
    "import pyautogui\n",
    "\n",
    "def get_game_state():\n",
    "    # Get the position of the browser window (you may need to adjust this)\n",
    "    try:\n",
    "        # Try to locate the game window on screen (requires the browser to be visible)\n",
    "        browser_window = pyautogui.getWindowsWithTitle(\"Bad Time Simulator\")[0]  # or \"Chrome\" if that's what appears in the title\n",
    "        \n",
    "        # Get window coordinates\n",
    "        x, y = browser_window.left, browser_window.top\n",
    "        width, height = browser_window.width, browser_window.height\n",
    "        \n",
    "        # Adjust these values to capture just the game area (not the browser UI)\n",
    "        game_x = x + 10  # Add padding to skip browser borders\n",
    "        game_y = y + 100  # Skip address bar and tabs\n",
    "        game_width = width - 20\n",
    "        game_height = height - 120\n",
    "        \n",
    "        # Capture the game area\n",
    "        screenshot = ImageGrab.grab(bbox=(game_x, game_y, game_x+game_width, game_y+game_height))\n",
    "    except:\n",
    "        # Fallback: capture entire screen if window detection fails\n",
    "        screenshot = ImageGrab.grab()\n",
    "    \n",
    "    # Process the image\n",
    "    screenshot = np.array(screenshot)\n",
    "    screenshot = cv2.cvtColor(screenshot, cv2.COLOR_RGB2GRAY)  # Convert to grayscale\n",
    "    screenshot = cv2.resize(screenshot, (84, 84))  # Resize for DQN input\n",
    "    return screenshot\n",
    "\n",
    "# Test it\n",
    "state = get_game_state()\n",
    "cv2.imshow('Game Capture', state)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0acb30b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
